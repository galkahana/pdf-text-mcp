# Claude Session Data - PDF Text MCP Project

## Project Context
- **Project**: PDF Text Extraction MCP Service
- **Current Phase**: Phase 4 - Monorepo Restructure ‚úÖ **COMPLETE**
- **Repository**: https://github.com/galkahana/pdf-text-mcp
- **Location**: `/Users/galk/Documents/projects/hummus_ai/pdf-text-mcp`
- **Status**: Phase 4 complete, ready for Phase 5 (Server Deployment)

## Git Workflow
**Standard Process** (use for all future phases):
1. Create feature branch from main: `git checkout -b phase-N-description`
2. Make changes and commit with descriptive messages
3. Push branch to remote: `git push -u origin phase-N-description`
4. Open Pull Request (PR) with comprehensive description
   - PR description should document all work regardless of number of commits
   - Better display in GitHub than individual commit messages
5. Merge PR to main after review/approval
6. Delete feature branch

**Benefits**:
- Clear PR descriptions provide complete context for each phase
- Easier to review changes in GitHub
- Better project history and documentation
- Cleaner commit history on main branch

## Code Patterns & Guidelines

### DRY Principle - Stream-Based Core Functions
- **Core functions work with streams**: `ExtractTextCore(IByteReaderWithPosition*)` and `ExtractMetadataCore(IByteReaderWithPosition*)` contain the actual extraction logic
- **File/Buffer operations are thin wrappers**: They create the appropriate stream and delegate to core functions
  - File operations: Open `InputFile` ‚Üí get stream ‚Üí call core
  - Buffer operations: Create `BufferByteReader` ‚Üí call core
- **Benefits**: Single source of truth for extraction logic, easy to add new stream sources (e.g., network streams, encrypted streams)

### Code Quality Standards
- Always refactor duplicate code into shared helper functions
- Prefer direct stream reading over temp file I/O for buffer operations
- Use custom IByteReaderWithPosition implementations for memory-backed data

### Native Addon Patterns
- Use `PDFTextString::ToUTF8String()` for proper Unicode handling in PDF metadata
- Use `PDFObjectCastPtr<T>` for managed pointers to PDF objects, except for `PDFObject` itself (use raw pointers)
- Implement `IByteReaderWithPosition` interface for custom stream sources (e.g., BufferByteReader for Node.js buffers)

## Completed Work

### Phase 1: PDF Parser
- ‚úÖ Native C++ integration with pdf-text-extraction library via CMake FetchContent (v1.1.9)
- ‚úÖ Text extraction from files and buffers
- ‚úÖ Metadata extraction from files and buffers
- ‚úÖ Bidirectional text support (Hebrew, Arabic, etc.)
- ‚úÖ Build system with CMake and cmake-js
- ‚úÖ TypeScript wrapper with proper types
- ‚úÖ Comprehensive test suite (28 unit tests + manual integration tests)
- ‚úÖ Custom stream support for buffer operations (BufferByteReader implementing IByteReaderWithPosition)

## Refactoring Completed
- ‚úÖ Code duplication eliminated between buffer and file operations
- ‚úÖ Direct stream reading for buffers - no temp files needed
- ‚úÖ BufferByteReader class implementing IByteReaderWithPosition for memory-backed PDF parsing
- ‚úÖ Core extraction logic shared via stream abstraction:
  - `ExtractTextCore(IByteReaderWithPosition*)` - works with any stream source
  - `ExtractMetadataCore(IByteReaderWithPosition*)` - works with any stream source
  - File operations: open InputFile ‚Üí get stream ‚Üí call core function
  - Buffer operations: create BufferByteReader ‚Üí call core function
- ‚úÖ Helper functions: SetMetadataField, GetStringFromPDFObject

## Bidi Algorithm Configuration
- ‚úÖ Bidi algorithm ALWAYS enabled (ICU library required)
- ‚úÖ Hardcoded to LTR (0) direction in native addon
- ‚úÖ `USE_BIDI ON` set in CMakeLists.txt before FetchContent
- ‚úÖ Compiles with `-DSUPPORT_ICU_BIDI=1` and `-DINCLUDE_UBIDI`
- ‚úÖ No configuration parameters - bidi is always-on
- ‚úÖ Proper Unicode text ordering for all extractions

## Timeout Implementation
- ‚úÖ Soft timeout using `withTimeout` wrapper
- ‚úÖ All 4 native methods wrapped: extractText, extractTextFromBuffer, getMetadata, getMetadataFromBuffer
- ‚ö†Ô∏è **Limitation**: Timeout is "soft" - rejects promise but native code continues running
- üìå **Future**: True cancellation requires N-API async workers (runs on separate thread)

## Dependency Management
- **pdf-text-extraction**: Fetched via CMake FetchContent (v1.1.9) from GitHub releases
  - SHA256 verified for reproducible builds (5bd63becb30cbf155a164dabde8df98cb5cc597bb0904f42367234df51873607)
  - No git submodules - cleaner repo
  - Build downloads and caches dependencies automatically
  - v1.1.9 adds support for custom stream input via IByteReaderWithPosition
- **Test Materials**: Copied into `test-materials/` directory
  - `HighLevelContentContext.pdf` - Simple test PDF
  - `GalKahanaCV2022.pdf` - Multi-page with Unicode metadata

## Build Commands
```bash
npm run build:native    # Build C++ addon (fetches pdf-text-extraction v1.1.9)
npm run rebuild         # Clean rebuild
npm run build          # Build native + TypeScript
npm test              # Run unit tests (Jest)
npm run test:manual   # Run manual integration tests
npm run test:all      # Run ALL tests (unit + manual)
```

## Test Organization
### Unit Tests (Jest - automated)
- `__tests__/pdf-extractor.test.ts` - 28 unit tests with content verification
- `__tests__/utils.test.ts` - Utility function tests
- Run automatically with `npm test`
- Run in CI/CD pipelines

### Manual Integration Tests
- `manual-tests/integration-test.js` - Comprehensive manual verification
  - Text extraction from files and buffers
  - Metadata extraction with Unicode (Hebrew) verification
  - Bidi direction handling (LTR/RTL)
  - Error handling scenarios
  - Colored output for easy visual verification
- Run with `npm run test:manual`
- Use during development for quick verification

## Testing Standards
- **Content Verification**: Tests verify actual extracted text content, not just length
- **Real PDFs**: Tests use actual PDF files from test materials (not mocks)
- **Expected Content**: Tests check for specific words/phrases to ensure extraction works correctly
  - Simple PDF: "Paths", "Squares", "Circles", "Rectangles"
  - CV PDF: "Gal Kahana", "Curriculum Vitae", "Tel Aviv"
  - Metadata: Hebrew title "◊ß◊ï◊®◊ï◊™ ◊ó◊ô◊ô◊ù" (proves Unicode handling)
- **Regular Execution**: Run `npm run test:all` regularly to catch regressions
- This is critical since C++ code doesn't have unit tests

## Design Decisions to Revisit

### 1. File Size / Timeout Limits (Parser vs MCP Layer)
**Current**: Parser has `maxFileSize` (100MB) and `timeout` (30s) options
**Question**: Should these be at parser level, MCP level, or both?
**Current Reasoning**:
- Parser level provides defense-in-depth and makes module reusable with built-in safety
- Protects native C++ code from memory exhaustion and runaway operations
- Fails fast before expensive native operations
**Future Consideration**:
- MCP server may want additional/different limits for quota management, rate limiting, user tiers
- Decision: Likely keep both - parser for self-protection, MCP for policy enforcement
**Status**: Tabled until MCP implementation. Current approach is reasonable.

### 2. Password-Protected PDF Support
**Current**: Not supported - password-protected PDFs will fail to parse
**Future Requirements**:
- Need to detect password-protected PDFs and provide clear error (vs generic parse failure)
- Support conversational password prompting in MCP context
- May need to use PDFWriter/PDFHummus functionality directly to check for encryption
- Consider adding to pdf-text-extraction library itself for broader benefit
**Implementation Considerations**:
- Error detection: Check if PDF is encrypted before attempting extraction
- Password handling: MCP server would manage password prompting/retry flow
- Security: Handle password securely, don't log or persist
**Status**: Post-MVP feature. Not required for initial release.

### 3. Buffer Support via Custom Stream
**Status**: ‚úÖ **COMPLETED** (November 2024)
**Implementation**:
- pdf-text-extraction v1.1.9 added `IByteReaderWithPosition` support
- Created `BufferByteReader` class implementing the interface for Node.js buffers
- `extractTextFromBuffer()` now uses direct stream reading (no temp files)
- `getMetadataFromBuffer()` now uses direct stream reading (no temp files)
**Benefits Achieved**:
- ‚úÖ Better performance - no disk I/O overhead
- ‚úÖ Reduced system resource usage - no temp file creation/cleanup
- ‚úÖ More memory efficient for large buffers
- ‚úÖ Cleaner code - removed TempFileGuard RAII class and WriteBufferToFile helper
**Technical Details**:
- `BufferByteReader` wraps Node.js `Buffer` data and position tracking
- Implements all required methods: `Read()`, `NotEnded()`, `SetPosition()`, `SetPositionFromEnd()`, `GetCurrentPosition()`, `Skip()`
- `TextExtraction::ExtractText(IByteReaderWithPosition*)` used for text extraction
- `PDFParser::StartPDFParsing(IByteReaderWithPosition*)` used for metadata extraction

## Phase 1: Complete ‚úÖ

**Repository Created**: November 3, 2024
- Initial commit: 25 files, 12,412 lines
- MIT License added
- All tests passing (28 unit + manual integration tests)

**Deliverables**:
- ‚úÖ Native C++ addon with TypeScript wrapper
- ‚úÖ Text extraction from files and buffers
- ‚úÖ Metadata extraction with Unicode support
- ‚úÖ Stream-based architecture (DRY principle)
- ‚úÖ Comprehensive test suite
- ‚úÖ Full documentation

## Phase 2: Complete ‚úÖ

**Completed**: November 2025

**Deliverables**:
- ‚úÖ MCP server implementation using `@modelcontextprotocol/sdk`
- ‚úÖ stdio transport (JSON-RPC over stdin/stdout)
- ‚úÖ Two tools: `extract_text` and `extract_metadata`
- ‚úÖ Integration with pdf-parser package
- ‚úÖ Comprehensive error handling with error codes
- ‚úÖ Environment-based configuration (MAX_FILE_SIZE, TIMEOUT)
- ‚úÖ Full test suite (18 unit tests)
- ‚úÖ Claude Desktop integration instructions

**Key Changes from Initial Plan**:
- Used stdio transport instead of HTTP/WebSocket (MCP standard for Claude Desktop)
- No worker pool needed (Claude Desktop manages process lifecycle)
- No authentication/authorization (parent-child process security model)

**Architecture**:
```
Claude Desktop (parent) spawns ‚Üí MCP Server (child)
                             ‚Üì
                    stdio (JSON-RPC messages)
                             ‚Üì
                    PdfExtractor (pdf-parser)
                             ‚Üì
                    Native C++ addon
```

**Configuration Refinements**:
- ‚úÖ Bidi always enabled (removed `enableBidi` parameter)
- ‚úÖ Timeout implemented (soft timeout - native code continues after rejection)
- ‚úÖ Documentation cleanup (removed duplicated content from root README)

**Documentation Structure**:
- `README.md` (root) - Architecture overview, links to package READMEs
- `packages/pdf-parser/README.md` - Parser API and usage
- `packages/mcp-server/README.md` - Server setup and troubleshooting
- `.claude-session-data.md` - Development context (this file)

## Phase 3: Example Agent with PydanticAI ‚úÖ

**Completed**: November 2025

**Deliverables**:
- ‚úÖ Python-based AI agent using PydanticAI framework
- ‚úÖ Google Gemini 2.5 Flash integration (free tier for accessibility)
- ‚úÖ MCPServerStdio client (spawns MCP server as subprocess)
- ‚úÖ Three CLI commands: summarize, extract, metadata
- ‚úÖ Full type safety with strict mypy configuration
- ‚úÖ Comprehensive test suite (10 unit tests with FunctionModel mocking)
- ‚úÖ Code quality tooling: ruff (linting), black (formatting), mypy (type checking)
- ‚úÖ uv package manager for fast Python dependency management

**Architecture**:
```
PydanticAI Agent (Python)
    ‚Üì stdio subprocess
MCP Server (Node.js)
    ‚Üì
Native C++ PDF Parser
```

**Key Decisions**:
- Switched from Anthropic Claude to Google Gemini for free tier access
- Used monorepo structure with Python excluded from npm workspaces
- Used FunctionModel for proper test mocking (not method replacement)
- All commands use absolute paths for PDF files

## Phase 4: Monorepo Restructure ‚úÖ

**Completed**: November 2025

**Deliverables**:
- ‚úÖ Removed npm workspace setup - packages are fully independent
- ‚úÖ Added Justfiles to all packages with common command interface
- ‚úÖ Root Justfile for convenience commands across all packages
- ‚úÖ Removed root package.json and package-lock.json
- ‚úÖ Fixed package dependencies: pdf-parser uses local TypeScript, mcp-server references pdf-parser via `file:../pdf-parser`
- ‚úÖ Updated all documentation with `just` usage

**Build System**:
- `just` command runner provides language-agnostic build interface
- Common verbs across all packages: build, test, clean, install
- Node.js packages: lint, format, dev
- Python package: lint, format, type-check, check, demo

**Benefits**:
- Language equality: Node.js and Python packages treated the same
- No build order issues: each package manages its own dependencies
- Simple interface: same commands work everywhere
- Company-style monorepo: scalable for multi-language development

## Phase 5: Server Deployment & Infrastructure ‚úÖ

**Completed**: November 2025
**PR**: https://github.com/galkahana/pdf-text-mcp/pull/6 (Merged)

**Deliverables**:
- ‚úÖ HTTP/SSE transport using MCP SDK StreamableHTTPServerTransport
- ‚úÖ Multi-stage Docker build with ARM64 support (Node 20 + native compilation)
- ‚úÖ Kubernetes manifests (namespace, configmap, deployment, service)
- ‚úÖ Production-ready Helm chart with 4 environment configurations
- ‚úÖ Minikube-first local development workflow
- ‚úÖ Health/readiness/liveness probes
- ‚úÖ API key authentication (Bearer token)
- ‚úÖ File upload support via base64-encoded content
- ‚úÖ Comprehensive documentation (k8s/README.md, helm/README.md)
- ‚úÖ Dual transport support in example-agent (stdio and HTTP/SSE)

**Key Technical Achievements**:
- **ARM64 Build Fix**: Position Independent Code (-fPIC) for all CMake targets
- **Runtime Dependencies**: Matched Debian versions (Bullseye) for libicu67 and libssl1.1
- **Docker Optimization**: Standard Release (-O2), sequential build (--jobs 1) for 12GB memory limit
- **Final Image Size**: 310MB (multi-stage build with bullseye-slim)
- **Helm Chart**: 4 values files (default, prod, dev, minikube) for all scenarios

**Deployment Options**:
1. **Raw K8s Manifests**: `kubectl apply -f packages/mcp-server/k8s/` - Quick start
2. **Helm Chart**: `helm install pdf-mcp ./helm-chart -f values-prod.yaml` - Production
3. **Docker Compose**: `docker-compose up` - Local development
4. **Minikube**: Full testing workflow with NodePort access

**Architecture Updates**:
```
Transport Modes:
1. stdio: Claude Desktop (parent-child process)
2. http: Remote deployment (HTTP + SSE streaming)

HTTP Mode Stack:
Client ‚Üí HTTP/SSE ‚Üí Express ‚Üí MCP Server ‚Üí PDF Parser ‚Üí Native C++
```

**Configuration**:
- TRANSPORT_MODE: 'stdio' (default) or 'http'
- PORT: 3000 (default)
- HOST: 0.0.0.0 (default)
- API_KEY: Optional Bearer token authentication
- MAX_FILE_SIZE: 100MB (default)
- TIMEOUT: 30s (default)

**Deployment Options**:
1. Docker Compose: `just docker-compose-up`
2. Kubernetes: `just k8s-apply`
3. Helm: `just helm-install`
4. Minikube: `just minikube-all` (recommended for development)

**Testing Levels**:
1. Unit tests: `just test`
2. Docker container: `just docker-build && just docker-run`
3. Full K8s deployment: `just minikube-full`

## Upcoming Phases

### Phase 6: Observability & Operations üìä
**Goal**: Production-ready monitoring, logging, and metrics

**Scope**:
- Structured JSON logging with correlation IDs
- Prometheus-compatible metrics (requests, errors, latency, PDF processing stats)
- Log aggregation (Loki preferred - evaluate vs ELK during implementation)
- Alerting integration
- Distributed tracing (OpenTelemetry - discuss benefits during implementation)

**Decisions**:
- **Metrics**: Prometheus (confirmed)
- **Logging**: Loki (needs education/comparison with ELK)
- **Tracing**: OpenTelemetry (needs discussion on benefits)

### Phase 7: True Timeout with Async Workers ‚è±Ô∏è
**Goal**: Proper cancellation and resource cleanup

**Scope**:
- N-API async workers for non-blocking extraction
- Move PDF processing to worker threads
- True timeout cancellation (not just promise rejection)
- Immediate resource cleanup on timeout
- Thread pool management

**Current Limitation**: Soft timeout rejects promise but native code continues running

### Phase 8: Password-Protected PDFs üîê
**Goal**: Handle encrypted PDF documents

**Scope**:
- Add password parameter to extraction APIs
- Support owner and user passwords
- Clear error messages for encrypted files
- Password validation and security considerations

### Phase 9: Advanced Bidi Configuration üî§
**Goal**: Configurable text direction handling

**Scope**:
- Optional RTL direction support
- Auto-detect text direction
- Per-document bidi settings
- API updates for bidi options

**Current State**: Bidi always enabled with hardcoded LTR direction

## Deferred Features
These items from the original future features list are **not planned**:
- ‚ùå Streaming API (page-by-page extraction)
- ‚ùå Bidi integration test (current tests sufficient)
- ‚ùå Performance metrics/benchmarking (covered by Phase 6 observability)

## Current Status (November 2025)

**Phase 5: COMPLETE ‚úÖ** - Ready for Phase 6

**Last Session Summary** (Completed Phase 5)

### ‚úÖ What We Accomplished:

1. **Fixed Docker Build Issues**:
   - ‚úÖ Resolved ARM64 Position Independent Code (-fPIC) compilation errors
   - ‚úÖ Added CMAKE_POSITION_INDEPENDENT_CODE=ON for all CMake targets
   - ‚úÖ Fixed runtime library version mismatches (Debian Bullseye compatibility)
   - ‚úÖ Added libicu67 and libssl1.1 runtime dependencies
   - ‚úÖ Used sequential build (--jobs 1) to work within 12GB Docker memory
   - ‚úÖ Successfully built 310MB production-ready image

2. **Deployed to Kubernetes**:
   - ‚úÖ Deployed to Minikube with all manifests working
   - ‚úÖ 3/3 pods running and healthy
   - ‚úÖ Health checks passing
   - ‚úÖ MCP protocol responding correctly via HTTP/SSE

3. **Created Production-Ready Helm Chart**:
   - ‚úÖ Complete Helm chart with templates and helper functions
   - ‚úÖ 4 environment-specific values files:
     - `values.yaml` - Production-ready defaults (3 replicas, ClusterIP)
     - `values-prod.yaml` - Full production (5-20 replicas, autoscaling, ingress+TLS)
     - `values-minikube.yaml` - Local development (1 replica, NodePort, minimal resources)
     - `values-dev.yaml` - Development (existing, uses 'dev' tag)
   - ‚úÖ Tested and validated with `helm lint` (passes)
   - ‚úÖ Successfully deployed to Minikube via Helm
   - ‚úÖ Service accessible and responding

4. **Documentation & Organization**:
   - ‚úÖ Added k8s/README.md - Quick start guide for raw manifests
   - ‚úÖ Added helm/README.md - Comprehensive Helm chart documentation
   - ‚úÖ Cleaned up empty root directories (docs/, helm/, k8s/, tools/)
   - ‚úÖ Clear separation: k8s for simple deployments, Helm for production

5. **Testing & Validation**:
   - ‚úÖ Docker container health checks passing
   - ‚úÖ Kubernetes deployment successful (3 pods running)
   - ‚úÖ Helm deployment successful (1 pod running with minikube values)
   - ‚úÖ MCP protocol initialization verified via curl
   - ‚úÖ End-to-end HTTP/SSE transport working

### üéØ How We Resolved the Docker Build OOM:

**Original Problem** (From previous session):
- Docker build failed at 94% compiling Encoding.cpp
- Error: `c++: fatal error: Killed signal terminated program cc1plus`
- Out of Memory (OOM) - compiler killed by system

**Resolution Steps** (This session):
1. **User increased Docker memory**: 12GB allocated
2. **First attempt**: Hit -fPIC errors on ARM64 during linking
   - Fixed: Added CMAKE_POSITION_INDEPENDENT_CODE=ON
   - Fixed: Set -fPIC in CMAKE_CXX_FLAGS and CMAKE_C_FLAGS
3. **Second attempt**: Runtime library version mismatch
   - Fixed: Changed runtime from node:20-slim to node:20-bullseye-slim
   - Fixed: Added libicu67 and libssl1.1 dependencies
4. **Final build**: Success with -O2 optimization (310MB image)
   - Used sequential build (--jobs 1) to stay within memory limit
   - Tested locally and in Minikube - all working

### üì¶ Final PR Summary

**Pull Request #6**: Phase 5 - Server Deployment & Infrastructure
- **Status**: ‚úÖ Merged to main
- **Commits**: 5 total
  1. Initial Phase 5 work (HTTP transport, Docker, K8s, Helm)
  2. ARM64 build fixes and optimizations
  3. Helm chart improvements (values files)
  4. Documentation (k8s/README.md, helm/README.md)
  5. Session data update

**Files Changed**: 37 files, +3162 lines
- Docker: Dockerfile, docker-compose.yml, .dockerignore
- Kubernetes: 5 manifest files + README
- Helm: Complete chart with 4 values files + README
- Documentation: LOCAL_DEVELOPMENT.md, various READMEs
- Example-agent: Dual transport support

### üìã Next Session: Phase 6 - Observability & Operations

**Goal**: Add production-ready monitoring, logging, and metrics

**Planned Scope**:
1. **Structured Logging**:
   - JSON format with correlation IDs
   - Log levels (debug, info, warn, error)
   - Request/response logging with timing

2. **Prometheus Metrics**:
   - Request counters (total, by tool, by status)
   - Response time histograms
   - PDF processing metrics (file size, page count, processing time)
   - Error rate tracking

3. **Health Monitoring**:
   - Detailed health checks with component status
   - Ready/liveness probe refinements
   - Graceful shutdown improvements

4. **Optional** (decide during implementation):
   - Log aggregation (Loki/ELK - evaluate options)
   - Distributed tracing (OpenTelemetry - discuss benefits)
   - Alerting rules (Prometheus AlertManager)

**Starting Point**:
- Create new branch: `phase-6-observability`
- Start with structured logging and Prometheus metrics
- Add monitoring to both local and K8s deployments
- Update Helm chart with observability features
