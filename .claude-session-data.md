# Claude Session Data - PDF Text MCP Project

## Project Context
- **Project**: PDF Text Extraction MCP Service
- **Current Phase**: Phase 1 - PDF Parser Package ✅ **COMPLETE**
- **Repository**: https://github.com/galkahana/pdf-text-mcp
- **Location**: `/Users/galk/Documents/projects/hummus_ai/pdf-text-mcp`
- **Status**: Phase 1 complete, ready for Phase 2

## Code Patterns & Guidelines

### DRY Principle - Stream-Based Core Functions
- **Core functions work with streams**: `ExtractTextCore(IByteReaderWithPosition*)` and `ExtractMetadataCore(IByteReaderWithPosition*)` contain the actual extraction logic
- **File/Buffer operations are thin wrappers**: They create the appropriate stream and delegate to core functions
  - File operations: Open `InputFile` → get stream → call core
  - Buffer operations: Create `BufferByteReader` → call core
- **Benefits**: Single source of truth for extraction logic, easy to add new stream sources (e.g., network streams, encrypted streams)

### Code Quality Standards
- Always refactor duplicate code into shared helper functions
- Prefer direct stream reading over temp file I/O for buffer operations
- Use custom IByteReaderWithPosition implementations for memory-backed data

### Native Addon Patterns
- Use `PDFTextString::ToUTF8String()` for proper Unicode handling in PDF metadata
- Use `PDFObjectCastPtr<T>` for managed pointers to PDF objects, except for `PDFObject` itself (use raw pointers)
- Implement `IByteReaderWithPosition` interface for custom stream sources (e.g., BufferByteReader for Node.js buffers)

## Completed Work

### Phase 1: PDF Parser
- ✅ Native C++ integration with pdf-text-extraction library via CMake FetchContent (v1.1.9)
- ✅ Text extraction from files and buffers
- ✅ Metadata extraction from files and buffers
- ✅ Bidirectional text support (Hebrew, Arabic, etc.)
- ✅ Build system with CMake and cmake-js
- ✅ TypeScript wrapper with proper types
- ✅ Comprehensive test suite (28 unit tests + manual integration tests)
- ✅ Custom stream support for buffer operations (BufferByteReader implementing IByteReaderWithPosition)

## Refactoring Completed
- ✅ Code duplication eliminated between buffer and file operations
- ✅ Direct stream reading for buffers - no temp files needed
- ✅ BufferByteReader class implementing IByteReaderWithPosition for memory-backed PDF parsing
- ✅ Core extraction logic shared via stream abstraction:
  - `ExtractTextCore(IByteReaderWithPosition*)` - works with any stream source
  - `ExtractMetadataCore(IByteReaderWithPosition*)` - works with any stream source
  - File operations: open InputFile → get stream → call core function
  - Buffer operations: create BufferByteReader → call core function
- ✅ Helper functions: SetMetadataField, GetStringFromPDFObject

## Bidi Algorithm Configuration
- ✅ Bidi algorithm always applied (not optional)
- ✅ Direction parameter: BidiDirection.LTR (0) or BidiDirection.RTL (1)
- ✅ Default direction: LTR (Left-to-Right)
- ✅ Changed from boolean `enableBidi` to numeric `bidiDirection` enum
- ✅ Proper Unicode text ordering for all extractions

## Dependency Management
- **pdf-text-extraction**: Fetched via CMake FetchContent (v1.1.9) from GitHub releases
  - SHA256 verified for reproducible builds (5bd63becb30cbf155a164dabde8df98cb5cc597bb0904f42367234df51873607)
  - No git submodules - cleaner repo
  - Build downloads and caches dependencies automatically
  - v1.1.9 adds support for custom stream input via IByteReaderWithPosition
- **Test Materials**: Copied into `test-materials/` directory
  - `HighLevelContentContext.pdf` - Simple test PDF
  - `GalKahanaCV2022.pdf` - Multi-page with Unicode metadata

## Build Commands
```bash
npm run build:native    # Build C++ addon (fetches pdf-text-extraction v1.1.9)
npm run rebuild         # Clean rebuild
npm run build          # Build native + TypeScript
npm test              # Run unit tests (Jest)
npm run test:manual   # Run manual integration tests
npm run test:all      # Run ALL tests (unit + manual)
```

## Test Organization
### Unit Tests (Jest - automated)
- `__tests__/pdf-extractor.test.ts` - 28 unit tests with content verification
- `__tests__/utils.test.ts` - Utility function tests
- Run automatically with `npm test`
- Run in CI/CD pipelines

### Manual Integration Tests
- `manual-tests/integration-test.js` - Comprehensive manual verification
  - Text extraction from files and buffers
  - Metadata extraction with Unicode (Hebrew) verification
  - Bidi direction handling (LTR/RTL)
  - Error handling scenarios
  - Colored output for easy visual verification
- Run with `npm run test:manual`
- Use during development for quick verification

## Testing Standards
- **Content Verification**: Tests verify actual extracted text content, not just length
- **Real PDFs**: Tests use actual PDF files from test materials (not mocks)
- **Expected Content**: Tests check for specific words/phrases to ensure extraction works correctly
  - Simple PDF: "Paths", "Squares", "Circles", "Rectangles"
  - CV PDF: "Gal Kahana", "Curriculum Vitae", "Tel Aviv"
  - Metadata: Hebrew title "קורות חיים" (proves Unicode handling)
- **Regular Execution**: Run `npm run test:all` regularly to catch regressions
- This is critical since C++ code doesn't have unit tests

## Design Decisions to Revisit

### 1. File Size / Timeout Limits (Parser vs MCP Layer)
**Current**: Parser has `maxFileSize` (100MB) and `timeout` (30s) options
**Question**: Should these be at parser level, MCP level, or both?
**Current Reasoning**:
- Parser level provides defense-in-depth and makes module reusable with built-in safety
- Protects native C++ code from memory exhaustion and runaway operations
- Fails fast before expensive native operations
**Future Consideration**:
- MCP server may want additional/different limits for quota management, rate limiting, user tiers
- Decision: Likely keep both - parser for self-protection, MCP for policy enforcement
**Status**: Tabled until MCP implementation. Current approach is reasonable.

### 2. Password-Protected PDF Support
**Current**: Not supported - password-protected PDFs will fail to parse
**Future Requirements**:
- Need to detect password-protected PDFs and provide clear error (vs generic parse failure)
- Support conversational password prompting in MCP context
- May need to use PDFWriter/PDFHummus functionality directly to check for encryption
- Consider adding to pdf-text-extraction library itself for broader benefit
**Implementation Considerations**:
- Error detection: Check if PDF is encrypted before attempting extraction
- Password handling: MCP server would manage password prompting/retry flow
- Security: Handle password securely, don't log or persist
**Status**: Post-MVP feature. Not required for initial release.

### 3. Buffer Support via Custom Stream
**Status**: ✅ **COMPLETED** (November 2024)
**Implementation**:
- pdf-text-extraction v1.1.9 added `IByteReaderWithPosition` support
- Created `BufferByteReader` class implementing the interface for Node.js buffers
- `extractTextFromBuffer()` now uses direct stream reading (no temp files)
- `getMetadataFromBuffer()` now uses direct stream reading (no temp files)
**Benefits Achieved**:
- ✅ Better performance - no disk I/O overhead
- ✅ Reduced system resource usage - no temp file creation/cleanup
- ✅ More memory efficient for large buffers
- ✅ Cleaner code - removed TempFileGuard RAII class and WriteBufferToFile helper
**Technical Details**:
- `BufferByteReader` wraps Node.js `Buffer` data and position tracking
- Implements all required methods: `Read()`, `NotEnded()`, `SetPosition()`, `SetPositionFromEnd()`, `GetCurrentPosition()`, `Skip()`
- `TextExtraction::ExtractText(IByteReaderWithPosition*)` used for text extraction
- `PDFParser::StartPDFParsing(IByteReaderWithPosition*)` used for metadata extraction

## Phase 1: Complete ✅

**Repository Created**: November 3, 2024
- Initial commit: 25 files, 12,412 lines
- MIT License added
- All tests passing (28 unit + manual integration tests)

**Deliverables**:
- ✅ Native C++ addon with TypeScript wrapper
- ✅ Text extraction from files and buffers
- ✅ Metadata extraction with Unicode support
- ✅ Stream-based architecture (DRY principle)
- ✅ Comprehensive test suite
- ✅ Full documentation

## Next Phase: Phase 2 - MCP Server Implementation

**Goals**:
- Implement MCP (Model Context Protocol) server
- HTTP/WebSocket API for PDF text extraction
- Tool registration and discovery
- Request/response handling with proper error management
- Integration with Phase 1 parser package

**Technical Stack** (to be determined):
- Node.js/TypeScript for server implementation
- Express or Fastify for HTTP server
- MCP SDK for protocol implementation
- Proper async/await patterns for concurrent processing

**Key Considerations**:
- Worker pool for concurrent PDF processing
- Rate limiting and quota management
- Streaming responses for large documents
- Proper error handling and reporting
- Health checks and monitoring endpoints

**Open Questions for Phase 2**:
1. Should we use Express, Fastify, or another framework?
2. What's the optimal worker pool size?
3. Do we need WebSocket support for long-running extractions?
4. How should we handle authentication/authorization?
5. What metrics should we expose?

## Future Phases
- Phase 3: Example agent implementation
- Phase 4: Infrastructure (Docker, Kubernetes, Helm)
