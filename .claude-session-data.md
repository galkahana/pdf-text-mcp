# Claude Session Data - PDF Text MCP Project

## Project Context
- **Project**: PDF Text Extraction MCP Service
- **Current Phase**: Phase 4 - Monorepo Restructure ‚úÖ **COMPLETE**
- **Repository**: https://github.com/galkahana/pdf-text-mcp
- **Location**: `/Users/galk/Documents/projects/hummus_ai/pdf-text-mcp`
- **Status**: Phase 4 complete, ready for Phase 5 (Server Deployment)

## Git Workflow
**Standard Process** (use for all future phases):
1. Create feature branch from main: `git checkout -b phase-N-description`
2. Make changes and commit with descriptive messages
3. Push branch to remote: `git push -u origin phase-N-description`
4. Open Pull Request (PR) with comprehensive description
   - PR description should document all work regardless of number of commits
   - Better display in GitHub than individual commit messages
5. Merge PR to main after review/approval
6. Delete feature branch

**Benefits**:
- Clear PR descriptions provide complete context for each phase
- Easier to review changes in GitHub
- Better project history and documentation
- Cleaner commit history on main branch

## Code Patterns & Guidelines

### DRY Principle - Stream-Based Core Functions
- **Core functions work with streams**: `ExtractTextCore(IByteReaderWithPosition*)` and `ExtractMetadataCore(IByteReaderWithPosition*)` contain the actual extraction logic
- **File/Buffer operations are thin wrappers**: They create the appropriate stream and delegate to core functions
  - File operations: Open `InputFile` ‚Üí get stream ‚Üí call core
  - Buffer operations: Create `BufferByteReader` ‚Üí call core
- **Benefits**: Single source of truth for extraction logic, easy to add new stream sources (e.g., network streams, encrypted streams)

### Code Quality Standards
- Always refactor duplicate code into shared helper functions
- Prefer direct stream reading over temp file I/O for buffer operations
- Use custom IByteReaderWithPosition implementations for memory-backed data

### Native Addon Patterns
- Use `PDFTextString::ToUTF8String()` for proper Unicode handling in PDF metadata
- Use `PDFObjectCastPtr<T>` for managed pointers to PDF objects, except for `PDFObject` itself (use raw pointers)
- Implement `IByteReaderWithPosition` interface for custom stream sources (e.g., BufferByteReader for Node.js buffers)

## Completed Work

### Phase 1: PDF Parser
- ‚úÖ Native C++ integration with pdf-text-extraction library via CMake FetchContent (v1.1.9)
- ‚úÖ Text extraction from files and buffers
- ‚úÖ Metadata extraction from files and buffers
- ‚úÖ Bidirectional text support (Hebrew, Arabic, etc.)
- ‚úÖ Build system with CMake and cmake-js
- ‚úÖ TypeScript wrapper with proper types
- ‚úÖ Comprehensive test suite (28 unit tests + manual integration tests)
- ‚úÖ Custom stream support for buffer operations (BufferByteReader implementing IByteReaderWithPosition)

## Refactoring Completed
- ‚úÖ Code duplication eliminated between buffer and file operations
- ‚úÖ Direct stream reading for buffers - no temp files needed
- ‚úÖ BufferByteReader class implementing IByteReaderWithPosition for memory-backed PDF parsing
- ‚úÖ Core extraction logic shared via stream abstraction:
  - `ExtractTextCore(IByteReaderWithPosition*)` - works with any stream source
  - `ExtractMetadataCore(IByteReaderWithPosition*)` - works with any stream source
  - File operations: open InputFile ‚Üí get stream ‚Üí call core function
  - Buffer operations: create BufferByteReader ‚Üí call core function
- ‚úÖ Helper functions: SetMetadataField, GetStringFromPDFObject

## Bidi Algorithm Configuration
- ‚úÖ Bidi algorithm ALWAYS enabled (ICU library required)
- ‚úÖ Hardcoded to LTR (0) direction in native addon
- ‚úÖ `USE_BIDI ON` set in CMakeLists.txt before FetchContent
- ‚úÖ Compiles with `-DSUPPORT_ICU_BIDI=1` and `-DINCLUDE_UBIDI`
- ‚úÖ No configuration parameters - bidi is always-on
- ‚úÖ Proper Unicode text ordering for all extractions

## Timeout Implementation
- ‚úÖ Soft timeout using `withTimeout` wrapper
- ‚úÖ All 4 native methods wrapped: extractText, extractTextFromBuffer, getMetadata, getMetadataFromBuffer
- ‚ö†Ô∏è **Limitation**: Timeout is "soft" - rejects promise but native code continues running
- üìå **Future**: True cancellation requires N-API async workers (runs on separate thread)

## Dependency Management
- **pdf-text-extraction**: Fetched via CMake FetchContent (v1.1.9) from GitHub releases
  - SHA256 verified for reproducible builds (5bd63becb30cbf155a164dabde8df98cb5cc597bb0904f42367234df51873607)
  - No git submodules - cleaner repo
  - Build downloads and caches dependencies automatically
  - v1.1.9 adds support for custom stream input via IByteReaderWithPosition
- **Test Materials**: Copied into `test-materials/` directory
  - `HighLevelContentContext.pdf` - Simple test PDF
  - `GalKahanaCV2022.pdf` - Multi-page with Unicode metadata

## Build Commands
```bash
npm run build:native    # Build C++ addon (fetches pdf-text-extraction v1.1.9)
npm run rebuild         # Clean rebuild
npm run build          # Build native + TypeScript
npm test              # Run unit tests (Jest)
npm run test:manual   # Run manual integration tests
npm run test:all      # Run ALL tests (unit + manual)
```

## Test Organization
### Unit Tests (Jest - automated)
- `__tests__/pdf-extractor.test.ts` - 28 unit tests with content verification
- `__tests__/utils.test.ts` - Utility function tests
- Run automatically with `npm test`
- Run in CI/CD pipelines

### Manual Integration Tests
- `manual-tests/integration-test.js` - Comprehensive manual verification
  - Text extraction from files and buffers
  - Metadata extraction with Unicode (Hebrew) verification
  - Bidi direction handling (LTR/RTL)
  - Error handling scenarios
  - Colored output for easy visual verification
- Run with `npm run test:manual`
- Use during development for quick verification

## Testing Standards
- **Content Verification**: Tests verify actual extracted text content, not just length
- **Real PDFs**: Tests use actual PDF files from test materials (not mocks)
- **Expected Content**: Tests check for specific words/phrases to ensure extraction works correctly
  - Simple PDF: "Paths", "Squares", "Circles", "Rectangles"
  - CV PDF: "Gal Kahana", "Curriculum Vitae", "Tel Aviv"
  - Metadata: Hebrew title "◊ß◊ï◊®◊ï◊™ ◊ó◊ô◊ô◊ù" (proves Unicode handling)
- **Regular Execution**: Run `npm run test:all` regularly to catch regressions
- This is critical since C++ code doesn't have unit tests

## Design Decisions to Revisit

### 1. File Size / Timeout Limits (Parser vs MCP Layer)
**Current**: Parser has `maxFileSize` (100MB) and `timeout` (30s) options
**Question**: Should these be at parser level, MCP level, or both?
**Current Reasoning**:
- Parser level provides defense-in-depth and makes module reusable with built-in safety
- Protects native C++ code from memory exhaustion and runaway operations
- Fails fast before expensive native operations
**Future Consideration**:
- MCP server may want additional/different limits for quota management, rate limiting, user tiers
- Decision: Likely keep both - parser for self-protection, MCP for policy enforcement
**Status**: Tabled until MCP implementation. Current approach is reasonable.

### 2. Password-Protected PDF Support
**Current**: Not supported - password-protected PDFs will fail to parse
**Future Requirements**:
- Need to detect password-protected PDFs and provide clear error (vs generic parse failure)
- Support conversational password prompting in MCP context
- May need to use PDFWriter/PDFHummus functionality directly to check for encryption
- Consider adding to pdf-text-extraction library itself for broader benefit
**Implementation Considerations**:
- Error detection: Check if PDF is encrypted before attempting extraction
- Password handling: MCP server would manage password prompting/retry flow
- Security: Handle password securely, don't log or persist
**Status**: Post-MVP feature. Not required for initial release.

### 3. Buffer Support via Custom Stream
**Status**: ‚úÖ **COMPLETED** (November 2024)
**Implementation**:
- pdf-text-extraction v1.1.9 added `IByteReaderWithPosition` support
- Created `BufferByteReader` class implementing the interface for Node.js buffers
- `extractTextFromBuffer()` now uses direct stream reading (no temp files)
- `getMetadataFromBuffer()` now uses direct stream reading (no temp files)
**Benefits Achieved**:
- ‚úÖ Better performance - no disk I/O overhead
- ‚úÖ Reduced system resource usage - no temp file creation/cleanup
- ‚úÖ More memory efficient for large buffers
- ‚úÖ Cleaner code - removed TempFileGuard RAII class and WriteBufferToFile helper
**Technical Details**:
- `BufferByteReader` wraps Node.js `Buffer` data and position tracking
- Implements all required methods: `Read()`, `NotEnded()`, `SetPosition()`, `SetPositionFromEnd()`, `GetCurrentPosition()`, `Skip()`
- `TextExtraction::ExtractText(IByteReaderWithPosition*)` used for text extraction
- `PDFParser::StartPDFParsing(IByteReaderWithPosition*)` used for metadata extraction

## Phase 1: Complete ‚úÖ

**Repository Created**: November 3, 2024
- Initial commit: 25 files, 12,412 lines
- MIT License added
- All tests passing (28 unit + manual integration tests)

**Deliverables**:
- ‚úÖ Native C++ addon with TypeScript wrapper
- ‚úÖ Text extraction from files and buffers
- ‚úÖ Metadata extraction with Unicode support
- ‚úÖ Stream-based architecture (DRY principle)
- ‚úÖ Comprehensive test suite
- ‚úÖ Full documentation

## Phase 2: Complete ‚úÖ

**Completed**: November 2025

**Deliverables**:
- ‚úÖ MCP server implementation using `@modelcontextprotocol/sdk`
- ‚úÖ stdio transport (JSON-RPC over stdin/stdout)
- ‚úÖ Two tools: `extract_text` and `extract_metadata`
- ‚úÖ Integration with pdf-parser package
- ‚úÖ Comprehensive error handling with error codes
- ‚úÖ Environment-based configuration (MAX_FILE_SIZE, TIMEOUT)
- ‚úÖ Full test suite (18 unit tests)
- ‚úÖ Claude Desktop integration instructions

**Key Changes from Initial Plan**:
- Used stdio transport instead of HTTP/WebSocket (MCP standard for Claude Desktop)
- No worker pool needed (Claude Desktop manages process lifecycle)
- No authentication/authorization (parent-child process security model)

**Architecture**:
```
Claude Desktop (parent) spawns ‚Üí MCP Server (child)
                             ‚Üì
                    stdio (JSON-RPC messages)
                             ‚Üì
                    PdfExtractor (pdf-parser)
                             ‚Üì
                    Native C++ addon
```

**Configuration Refinements**:
- ‚úÖ Bidi always enabled (removed `enableBidi` parameter)
- ‚úÖ Timeout implemented (soft timeout - native code continues after rejection)
- ‚úÖ Documentation cleanup (removed duplicated content from root README)

**Documentation Structure**:
- `README.md` (root) - Architecture overview, links to package READMEs
- `packages/pdf-parser/README.md` - Parser API and usage
- `packages/mcp-server/README.md` - Server setup and troubleshooting
- `.claude-session-data.md` - Development context (this file)

## Phase 3: Example Agent with PydanticAI ‚úÖ

**Completed**: November 2025

**Deliverables**:
- ‚úÖ Python-based AI agent using PydanticAI framework
- ‚úÖ Google Gemini 2.5 Flash integration (free tier for accessibility)
- ‚úÖ MCPServerStdio client (spawns MCP server as subprocess)
- ‚úÖ Three CLI commands: summarize, extract, metadata
- ‚úÖ Full type safety with strict mypy configuration
- ‚úÖ Comprehensive test suite (10 unit tests with FunctionModel mocking)
- ‚úÖ Code quality tooling: ruff (linting), black (formatting), mypy (type checking)
- ‚úÖ uv package manager for fast Python dependency management

**Architecture**:
```
PydanticAI Agent (Python)
    ‚Üì stdio subprocess
MCP Server (Node.js)
    ‚Üì
Native C++ PDF Parser
```

**Key Decisions**:
- Switched from Anthropic Claude to Google Gemini for free tier access
- Used monorepo structure with Python excluded from npm workspaces
- Used FunctionModel for proper test mocking (not method replacement)
- All commands use absolute paths for PDF files

## Phase 4: Monorepo Restructure ‚úÖ

**Completed**: November 2025

**Deliverables**:
- ‚úÖ Removed npm workspace setup - packages are fully independent
- ‚úÖ Added Justfiles to all packages with common command interface
- ‚úÖ Root Justfile for convenience commands across all packages
- ‚úÖ Removed root package.json and package-lock.json
- ‚úÖ Fixed package dependencies: pdf-parser uses local TypeScript, mcp-server references pdf-parser via `file:../pdf-parser`
- ‚úÖ Updated all documentation with `just` usage

**Build System**:
- `just` command runner provides language-agnostic build interface
- Common verbs across all packages: build, test, clean, install
- Node.js packages: lint, format, dev
- Python package: lint, format, type-check, check, demo

**Benefits**:
- Language equality: Node.js and Python packages treated the same
- No build order issues: each package manages its own dependencies
- Simple interface: same commands work everywhere
- Company-style monorepo: scalable for multi-language development

## Phase 5: Server Deployment & Infrastructure ‚úÖ

**Completed**: November 2025

**Deliverables**:
- ‚úÖ HTTP/SSE transport using MCP SDK StreamableHTTPServerTransport
- ‚úÖ Multi-stage Docker build (Node 20 + native compilation)
- ‚úÖ Kubernetes manifests (namespace, configmap, deployment, service)
- ‚úÖ Complete Helm chart with production and development values
- ‚úÖ Minikube-first local development workflow
- ‚úÖ Health/readiness/liveness probes
- ‚úÖ API key authentication (Bearer token)
- ‚úÖ File upload support via base64-encoded content
- ‚úÖ Comprehensive Justfile commands for all workflows
- ‚úÖ Full documentation (LOCAL_DEVELOPMENT.md)

**Key Decisions**:
- Used HTTP/SSE instead of WebSocket (MCP SDK standard)
- Minikube for local testing (no registry required)
- NodePort service type for development
- Multi-stage build for optimized image size
- Non-root user security (mcpserver:1000)

**Architecture Updates**:
```
Transport Modes:
1. stdio: Claude Desktop (parent-child process)
2. http: Remote deployment (HTTP + SSE streaming)

HTTP Mode Stack:
Client ‚Üí HTTP/SSE ‚Üí Express ‚Üí MCP Server ‚Üí PDF Parser ‚Üí Native C++
```

**Configuration**:
- TRANSPORT_MODE: 'stdio' (default) or 'http'
- PORT: 3000 (default)
- HOST: 0.0.0.0 (default)
- API_KEY: Optional Bearer token authentication
- MAX_FILE_SIZE: 100MB (default)
- TIMEOUT: 30s (default)

**Deployment Options**:
1. Docker Compose: `just docker-compose-up`
2. Kubernetes: `just k8s-apply`
3. Helm: `just helm-install`
4. Minikube: `just minikube-all` (recommended for development)

**Testing Levels**:
1. Unit tests: `just test`
2. Docker container: `just docker-build && just docker-run`
3. Full K8s deployment: `just minikube-full`

## Upcoming Phases

### Phase 6: Observability & Operations üìä
**Goal**: Production-ready monitoring, logging, and metrics

**Scope**:
- Structured JSON logging with correlation IDs
- Prometheus-compatible metrics (requests, errors, latency, PDF processing stats)
- Log aggregation (Loki preferred - evaluate vs ELK during implementation)
- Alerting integration
- Distributed tracing (OpenTelemetry - discuss benefits during implementation)

**Decisions**:
- **Metrics**: Prometheus (confirmed)
- **Logging**: Loki (needs education/comparison with ELK)
- **Tracing**: OpenTelemetry (needs discussion on benefits)

### Phase 7: True Timeout with Async Workers ‚è±Ô∏è
**Goal**: Proper cancellation and resource cleanup

**Scope**:
- N-API async workers for non-blocking extraction
- Move PDF processing to worker threads
- True timeout cancellation (not just promise rejection)
- Immediate resource cleanup on timeout
- Thread pool management

**Current Limitation**: Soft timeout rejects promise but native code continues running

### Phase 8: Password-Protected PDFs üîê
**Goal**: Handle encrypted PDF documents

**Scope**:
- Add password parameter to extraction APIs
- Support owner and user passwords
- Clear error messages for encrypted files
- Password validation and security considerations

### Phase 9: Advanced Bidi Configuration üî§
**Goal**: Configurable text direction handling

**Scope**:
- Optional RTL direction support
- Auto-detect text direction
- Per-document bidi settings
- API updates for bidi options

**Current State**: Bidi always enabled with hardcoded LTR direction

## Deferred Features
These items from the original future features list are **not planned**:
- ‚ùå Streaming API (page-by-page extraction)
- ‚ùå Bidi integration test (current tests sufficient)
- ‚ùå Performance metrics/benchmarking (covered by Phase 6 observability)

## Current Session Status (November 2025) - Weekend Break

**Phase 5 Progress - Session End Summary**

### ‚úÖ Completed This Session:

1. **Infrastructure Code Complete**:
   - ‚úÖ HTTP/SSE transport with authentication (API keys)
   - ‚úÖ Base64 file upload for remote PDF processing
   - ‚úÖ Docker configuration (Dockerfile, docker-compose.yml)
   - ‚úÖ Kubernetes manifests (namespace, deployment, service, configmap)
   - ‚úÖ Helm charts with production & dev values
   - ‚úÖ Health/readiness/metrics endpoints
   - ‚úÖ Comprehensive documentation and justfile commands

2. **Bug Fixes**:
   - ‚úÖ Fixed ICU library version (libicu67 ‚Üí libicu72 for Debian Bookworm)
   - ‚úÖ Fixed CMake version compatibility (upgraded to CMake 4.1.2 via pip for CMake 3.24+ support)

3. **Example-Agent Dual Transport Support** (commit 2be2b28):
   - ‚úÖ Added MCPServerSSE support for remote HTTP/SSE connections
   - ‚úÖ CLI options: `--mcp-url` and `--mcp-api-key`
   - ‚úÖ Environment variable support: `MCP_API_KEY`
   - ‚úÖ Backward compatible with existing stdio mode
   - ‚úÖ Bearer token authentication via Authorization header

   **Usage**:
   ```bash
   # Local mode (stdio):
   uv run pdf-summarizer summarize examples/doc.pdf

   # Remote mode (HTTP/SSE):
   uv run pdf-summarizer summarize \
     --mcp-url http://localhost:3000/mcp \
     --mcp-api-key YOUR_KEY \
     examples/doc.pdf
   ```

### ‚ö†Ô∏è Blocked: Docker Build OOM Issue

**Problem**:
- Docker build fails at 94% when compiling TextExtraction library (Encoding.cpp)
- Error: `c++: fatal error: Killed signal terminated program cc1plus`
- Out of Memory (OOM) - compiler process killed by system
- Retry attempts fail at same point

**Root Cause**:
- TextExtraction C++ library requires significant memory to compile
- Docker Desktop doesn't have enough memory allocated

**Solution Required (MUST DO BEFORE CONTINUING)**:
1. **Increase Docker Memory Allocation**:
   - Open Docker Desktop ‚Üí Settings/Preferences ‚Üí Resources
   - Increase memory to **8GB minimum** (currently likely 2-4GB)
   - Click "Apply & Restart"

2. **Alternative if memory increase doesn't work**:
   - Modify Dockerfile to use sequential build: change to `RUN npm run build:native -- --jobs 1`
   - This trades speed for lower memory usage

### üìã Next Session Plan (AFTER Weekend)

**DECISION**: Must fix Docker build and test full deployment before creating PR

**Required Steps**:
1. **Fix Docker Memory** (user action needed):
   - Increase Docker Desktop memory allocation to 8GB+
   - Restart Docker Desktop

2. **Complete Docker Build**:
   ```bash
   cd packages/mcp-server
   just docker-build
   # Should complete successfully after memory increase
   ```

3. **Test Docker Container Locally**:
   ```bash
   # Run container
   just docker-run

   # In another terminal, test endpoints:
   curl http://localhost:3000/health
   curl http://localhost:3000/ready
   curl http://localhost:3000/metrics
   ```

4. **Deploy to Minikube**:
   ```bash
   # Complete workflow (start + build + deploy)
   just minikube-all

   # Get service URL
   URL=$(just minikube-url)

   # Test deployment
   just minikube-test
   ```

5. **Test Example-Agent with Remote Server**:
   ```bash
   cd ../example-agent

   # Get minikube URL from step 4
   MINIKUBE_URL="http://192.168.xx.xx:xxxxx"  # from minikube-url

   # Test remote connection
   uv run pdf-summarizer summarize \
     --mcp-url ${MINIKUBE_URL}/mcp \
     examples/GalKahanaCV2022.pdf
   ```

6. **Verify Everything Works**:
   - Local Docker container responds correctly
   - Minikube deployment healthy
   - Example-agent successfully connects remotely
   - PDF extraction works end-to-end

7. **Create Pull Request**:
   - Comprehensive PR description documenting Phase 5
   - Include testing results from Docker and minikube
   - Document any remaining limitations

### üìä Current Branch Status

**Branch**: `phase-5-server-deployment`
**Commits**: 8 total (all code complete)
1. `512e267` - Add HTTP/SSE transport and remote deployment support
2. `2b1f28a` - Add complete deployment infrastructure
3. `26f9686` - Update session data
4. `f28a9a9` - Fix ICU library version
5. `21dda03` - Fix CMakeLists.txt for CMake compatibility
6. `20b95f1` - Install CMake 3.24+ via pip
7. `a84194b` - Update session data with testing progress
8. `2be2b28` - Add dual transport support to example-agent

**Status**: All code committed, ready for testing once Docker memory fixed

### üéØ Critical Path to PR

```
Fix Docker Memory (8GB+)
    ‚Üì
Docker Build Success
    ‚Üì
Test Docker Container (health checks)
    ‚Üì
Minikube Deploy (just minikube-all)
    ‚Üì
Test Remote Connection (example-agent ‚Üí minikube)
    ‚Üì
Create Pull Request
```

### üìù Session Notes

- User leaving for weekend
- Will resume testing after Docker memory fix
- All code is complete and committed
- Only testing/validation remains before PR
