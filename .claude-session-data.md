# Claude Session Data - PDF Text MCP Project

## Project Context
- **Project**: PDF Text Extraction MCP Service
- **Current Phase**: Phase 4 - Monorepo Restructure ‚úÖ **COMPLETE**
- **Repository**: https://github.com/galkahana/pdf-text-mcp
- **Location**: `/Users/galk/Documents/projects/hummus_ai/pdf-text-mcp`
- **Status**: Phase 4 complete, ready for Phase 5 (Server Deployment)

## Git Workflow
**Standard Process** (use for all future phases):
1. Create feature branch from main: `git checkout -b phase-N-description`
2. Make changes and commit with descriptive messages
3. Push branch to remote: `git push -u origin phase-N-description`
4. Open Pull Request (PR) with comprehensive description
   - PR description should document all work regardless of number of commits
   - Better display in GitHub than individual commit messages
5. Merge PR to main after review/approval
6. Delete feature branch

**Benefits**:
- Clear PR descriptions provide complete context for each phase
- Easier to review changes in GitHub
- Better project history and documentation
- Cleaner commit history on main branch

## Code Patterns & Guidelines

### DRY Principle - Stream-Based Core Functions
- **Core functions work with streams**: `ExtractTextCore(IByteReaderWithPosition*)` and `ExtractMetadataCore(IByteReaderWithPosition*)` contain the actual extraction logic
- **File/Buffer operations are thin wrappers**: They create the appropriate stream and delegate to core functions
  - File operations: Open `InputFile` ‚Üí get stream ‚Üí call core
  - Buffer operations: Create `BufferByteReader` ‚Üí call core
- **Benefits**: Single source of truth for extraction logic, easy to add new stream sources (e.g., network streams, encrypted streams)

### Code Quality Standards
- Always refactor duplicate code into shared helper functions
- Prefer direct stream reading over temp file I/O for buffer operations
- Use custom IByteReaderWithPosition implementations for memory-backed data

### Native Addon Patterns
- Use `PDFTextString::ToUTF8String()` for proper Unicode handling in PDF metadata
- Use `PDFObjectCastPtr<T>` for managed pointers to PDF objects, except for `PDFObject` itself (use raw pointers)
- Implement `IByteReaderWithPosition` interface for custom stream sources (e.g., BufferByteReader for Node.js buffers)

## Completed Work

### Phase 1: PDF Parser
- ‚úÖ Native C++ integration with pdf-text-extraction library via CMake FetchContent (v1.1.9)
- ‚úÖ Text extraction from files and buffers
- ‚úÖ Metadata extraction from files and buffers
- ‚úÖ Bidirectional text support (Hebrew, Arabic, etc.)
- ‚úÖ Build system with CMake and cmake-js
- ‚úÖ TypeScript wrapper with proper types
- ‚úÖ Comprehensive test suite (28 unit tests + manual integration tests)
- ‚úÖ Custom stream support for buffer operations (BufferByteReader implementing IByteReaderWithPosition)

## Refactoring Completed
- ‚úÖ Code duplication eliminated between buffer and file operations
- ‚úÖ Direct stream reading for buffers - no temp files needed
- ‚úÖ BufferByteReader class implementing IByteReaderWithPosition for memory-backed PDF parsing
- ‚úÖ Core extraction logic shared via stream abstraction:
  - `ExtractTextCore(IByteReaderWithPosition*)` - works with any stream source
  - `ExtractMetadataCore(IByteReaderWithPosition*)` - works with any stream source
  - File operations: open InputFile ‚Üí get stream ‚Üí call core function
  - Buffer operations: create BufferByteReader ‚Üí call core function
- ‚úÖ Helper functions: SetMetadataField, GetStringFromPDFObject

## Bidi Algorithm Configuration
- ‚úÖ Bidi algorithm ALWAYS enabled (ICU library required)
- ‚úÖ Hardcoded to LTR (0) direction in native addon
- ‚úÖ `USE_BIDI ON` set in CMakeLists.txt before FetchContent
- ‚úÖ Compiles with `-DSUPPORT_ICU_BIDI=1` and `-DINCLUDE_UBIDI`
- ‚úÖ No configuration parameters - bidi is always-on
- ‚úÖ Proper Unicode text ordering for all extractions

## Timeout Implementation
- ‚úÖ Soft timeout using `withTimeout` wrapper
- ‚úÖ All 4 native methods wrapped: extractText, extractTextFromBuffer, getMetadata, getMetadataFromBuffer
- ‚ö†Ô∏è **Limitation**: Timeout is "soft" - rejects promise but native code continues running
- üìå **Future**: True cancellation requires N-API async workers (runs on separate thread)

## Dependency Management
- **pdf-text-extraction**: Fetched via CMake FetchContent (v1.1.9) from GitHub releases
  - SHA256 verified for reproducible builds (5bd63becb30cbf155a164dabde8df98cb5cc597bb0904f42367234df51873607)
  - No git submodules - cleaner repo
  - Build downloads and caches dependencies automatically
  - v1.1.9 adds support for custom stream input via IByteReaderWithPosition
- **Test Materials**: Copied into `test-materials/` directory
  - `HighLevelContentContext.pdf` - Simple test PDF
  - `GalKahanaCV2022.pdf` - Multi-page with Unicode metadata

## Build Commands
```bash
npm run build:native    # Build C++ addon (fetches pdf-text-extraction v1.1.9)
npm run rebuild         # Clean rebuild
npm run build          # Build native + TypeScript
npm test              # Run unit tests (Jest)
npm run test:manual   # Run manual integration tests
npm run test:all      # Run ALL tests (unit + manual)
```

## Test Organization
### Unit Tests (Jest - automated)
- `__tests__/pdf-extractor.test.ts` - 28 unit tests with content verification
- `__tests__/utils.test.ts` - Utility function tests
- Run automatically with `npm test`
- Run in CI/CD pipelines

### Manual Integration Tests
- `manual-tests/integration-test.js` - Comprehensive manual verification
  - Text extraction from files and buffers
  - Metadata extraction with Unicode (Hebrew) verification
  - Bidi direction handling (LTR/RTL)
  - Error handling scenarios
  - Colored output for easy visual verification
- Run with `npm run test:manual`
- Use during development for quick verification

## Testing Standards
- **Content Verification**: Tests verify actual extracted text content, not just length
- **Real PDFs**: Tests use actual PDF files from test materials (not mocks)
- **Expected Content**: Tests check for specific words/phrases to ensure extraction works correctly
  - Simple PDF: "Paths", "Squares", "Circles", "Rectangles"
  - CV PDF: "Gal Kahana", "Curriculum Vitae", "Tel Aviv"
  - Metadata: Hebrew title "◊ß◊ï◊®◊ï◊™ ◊ó◊ô◊ô◊ù" (proves Unicode handling)
- **Regular Execution**: Run `npm run test:all` regularly to catch regressions
- This is critical since C++ code doesn't have unit tests

## Design Decisions to Revisit

### 1. File Size / Timeout Limits (Parser vs MCP Layer)
**Current**: Parser has `maxFileSize` (100MB) and `timeout` (30s) options
**Question**: Should these be at parser level, MCP level, or both?
**Current Reasoning**:
- Parser level provides defense-in-depth and makes module reusable with built-in safety
- Protects native C++ code from memory exhaustion and runaway operations
- Fails fast before expensive native operations
**Future Consideration**:
- MCP server may want additional/different limits for quota management, rate limiting, user tiers
- Decision: Likely keep both - parser for self-protection, MCP for policy enforcement
**Status**: Tabled until MCP implementation. Current approach is reasonable.

### 2. Password-Protected PDF Support
**Current**: Not supported - password-protected PDFs will fail to parse
**Future Requirements**:
- Need to detect password-protected PDFs and provide clear error (vs generic parse failure)
- Support conversational password prompting in MCP context
- May need to use PDFWriter/PDFHummus functionality directly to check for encryption
- Consider adding to pdf-text-extraction library itself for broader benefit
**Implementation Considerations**:
- Error detection: Check if PDF is encrypted before attempting extraction
- Password handling: MCP server would manage password prompting/retry flow
- Security: Handle password securely, don't log or persist
**Status**: Post-MVP feature. Not required for initial release.

### 3. Buffer Support via Custom Stream
**Status**: ‚úÖ **COMPLETED** (November 2024)
**Implementation**:
- pdf-text-extraction v1.1.9 added `IByteReaderWithPosition` support
- Created `BufferByteReader` class implementing the interface for Node.js buffers
- `extractTextFromBuffer()` now uses direct stream reading (no temp files)
- `getMetadataFromBuffer()` now uses direct stream reading (no temp files)
**Benefits Achieved**:
- ‚úÖ Better performance - no disk I/O overhead
- ‚úÖ Reduced system resource usage - no temp file creation/cleanup
- ‚úÖ More memory efficient for large buffers
- ‚úÖ Cleaner code - removed TempFileGuard RAII class and WriteBufferToFile helper
**Technical Details**:
- `BufferByteReader` wraps Node.js `Buffer` data and position tracking
- Implements all required methods: `Read()`, `NotEnded()`, `SetPosition()`, `SetPositionFromEnd()`, `GetCurrentPosition()`, `Skip()`
- `TextExtraction::ExtractText(IByteReaderWithPosition*)` used for text extraction
- `PDFParser::StartPDFParsing(IByteReaderWithPosition*)` used for metadata extraction

## Phase 1: Complete ‚úÖ

**Repository Created**: November 3, 2024
- Initial commit: 25 files, 12,412 lines
- MIT License added
- All tests passing (28 unit + manual integration tests)

**Deliverables**:
- ‚úÖ Native C++ addon with TypeScript wrapper
- ‚úÖ Text extraction from files and buffers
- ‚úÖ Metadata extraction with Unicode support
- ‚úÖ Stream-based architecture (DRY principle)
- ‚úÖ Comprehensive test suite
- ‚úÖ Full documentation

## Phase 2: Complete ‚úÖ

**Completed**: November 2025

**Deliverables**:
- ‚úÖ MCP server implementation using `@modelcontextprotocol/sdk`
- ‚úÖ stdio transport (JSON-RPC over stdin/stdout)
- ‚úÖ Two tools: `extract_text` and `extract_metadata`
- ‚úÖ Integration with pdf-parser package
- ‚úÖ Comprehensive error handling with error codes
- ‚úÖ Environment-based configuration (MAX_FILE_SIZE, TIMEOUT)
- ‚úÖ Full test suite (18 unit tests)
- ‚úÖ Claude Desktop integration instructions

**Key Changes from Initial Plan**:
- Used stdio transport instead of HTTP/WebSocket (MCP standard for Claude Desktop)
- No worker pool needed (Claude Desktop manages process lifecycle)
- No authentication/authorization (parent-child process security model)

**Architecture**:
```
Claude Desktop (parent) spawns ‚Üí MCP Server (child)
                             ‚Üì
                    stdio (JSON-RPC messages)
                             ‚Üì
                    PdfExtractor (pdf-parser)
                             ‚Üì
                    Native C++ addon
```

**Configuration Refinements**:
- ‚úÖ Bidi always enabled (removed `enableBidi` parameter)
- ‚úÖ Timeout implemented (soft timeout - native code continues after rejection)
- ‚úÖ Documentation cleanup (removed duplicated content from root README)

**Documentation Structure**:
- `README.md` (root) - Architecture overview, links to package READMEs
- `packages/pdf-parser/README.md` - Parser API and usage
- `packages/mcp-server/README.md` - Server setup and troubleshooting
- `.claude-session-data.md` - Development context (this file)

## Phase 3: Example Agent with PydanticAI ‚úÖ

**Completed**: November 2025

**Deliverables**:
- ‚úÖ Python-based AI agent using PydanticAI framework
- ‚úÖ Google Gemini 2.5 Flash integration (free tier for accessibility)
- ‚úÖ MCPServerStdio client (spawns MCP server as subprocess)
- ‚úÖ Three CLI commands: summarize, extract, metadata
- ‚úÖ Full type safety with strict mypy configuration
- ‚úÖ Comprehensive test suite (10 unit tests with FunctionModel mocking)
- ‚úÖ Code quality tooling: ruff (linting), black (formatting), mypy (type checking)
- ‚úÖ uv package manager for fast Python dependency management

**Architecture**:
```
PydanticAI Agent (Python)
    ‚Üì stdio subprocess
MCP Server (Node.js)
    ‚Üì
Native C++ PDF Parser
```

**Key Decisions**:
- Switched from Anthropic Claude to Google Gemini for free tier access
- Used monorepo structure with Python excluded from npm workspaces
- Used FunctionModel for proper test mocking (not method replacement)
- All commands use absolute paths for PDF files

## Phase 4: Monorepo Restructure ‚úÖ

**Completed**: November 2025

**Deliverables**:
- ‚úÖ Removed npm workspace setup - packages are fully independent
- ‚úÖ Added Justfiles to all packages with common command interface
- ‚úÖ Root Justfile for convenience commands across all packages
- ‚úÖ Removed root package.json and package-lock.json
- ‚úÖ Fixed package dependencies: pdf-parser uses local TypeScript, mcp-server references pdf-parser via `file:../pdf-parser`
- ‚úÖ Updated all documentation with `just` usage

**Build System**:
- `just` command runner provides language-agnostic build interface
- Common verbs across all packages: build, test, clean, install
- Node.js packages: lint, format, dev
- Python package: lint, format, type-check, check, demo

**Benefits**:
- Language equality: Node.js and Python packages treated the same
- No build order issues: each package manages its own dependencies
- Simple interface: same commands work everywhere
- Company-style monorepo: scalable for multi-language development

## Upcoming Phases

### Phase 5: Server Deployment & Infrastructure üöÄ
**Goal**: Deploy MCP server as remote service for production use

**Scope**:
- Docker containerization (multi-stage build for native compilation)
- Kubernetes deployment manifests
- Helm chart for parameterized deployments
- HTTP/WebSocket transport (alternative to stdio)
- Health checks and graceful shutdown

**Target Platform**: GKE (Google Kubernetes Engine)
**Multi-tenancy**: Not required initially
**Authentication**: TBD during implementation

### Phase 6: Observability & Operations üìä
**Goal**: Production-ready monitoring, logging, and metrics

**Scope**:
- Structured JSON logging with correlation IDs
- Prometheus-compatible metrics (requests, errors, latency, PDF processing stats)
- Log aggregation (Loki preferred - evaluate vs ELK during implementation)
- Alerting integration
- Distributed tracing (OpenTelemetry - discuss benefits during implementation)

**Decisions**:
- **Metrics**: Prometheus (confirmed)
- **Logging**: Loki (needs education/comparison with ELK)
- **Tracing**: OpenTelemetry (needs discussion on benefits)

### Phase 7: True Timeout with Async Workers ‚è±Ô∏è
**Goal**: Proper cancellation and resource cleanup

**Scope**:
- N-API async workers for non-blocking extraction
- Move PDF processing to worker threads
- True timeout cancellation (not just promise rejection)
- Immediate resource cleanup on timeout
- Thread pool management

**Current Limitation**: Soft timeout rejects promise but native code continues running

### Phase 8: Password-Protected PDFs üîê
**Goal**: Handle encrypted PDF documents

**Scope**:
- Add password parameter to extraction APIs
- Support owner and user passwords
- Clear error messages for encrypted files
- Password validation and security considerations

### Phase 9: Advanced Bidi Configuration üî§
**Goal**: Configurable text direction handling

**Scope**:
- Optional RTL direction support
- Auto-detect text direction
- Per-document bidi settings
- API updates for bidi options

**Current State**: Bidi always enabled with hardcoded LTR direction

## Deferred Features
These items from the original future features list are **not planned**:
- ‚ùå Streaming API (page-by-page extraction)
- ‚ùå Bidi integration test (current tests sufficient)
- ‚ùå Performance metrics/benchmarking (covered by Phase 6 observability)
